{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial de introducción a Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    NEGATIVE = \" NEGATIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        if self.score >= 4:\n",
    "            return Sentiment.POSITIVE\n",
    "        else:\n",
    "            return Sentiment.NEUTRAL\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_name = \"./data/Books_small.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0].sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [x.text for x in training]\n",
    "train_y = [x.sentiment for x in training]\n",
    "\n",
    "test_x = [x.text for x in test]\n",
    "test_y = [x.sentiment for x in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización 'Bag of words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Two steps vectoritation\n",
    "# vectorizer.fit(train_x)\n",
    "# train_x_vectors = vectorizer.transform(train_x)\n",
    "\n",
    "# All in one step\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Every new Myke Cole book is better than the last, and this is no exception. If you haven't read the Shadow Ops series before start with Control Point, but go ahead and order Fortress Frontier and Breach Zone as well - you're going to want them.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 7372), (1, 7372))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_vectors[0].shape, train_x_vectors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U9')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf_tree = tree.DecisionTreeClassifier()\n",
    "clf_tree.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U9')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_nbg = GaussianNB()\n",
    "clf_nbg.fit(train_x_vectors.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U9')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nbg.predict(test_x_vectors[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_lgr = LogisticRegression()\n",
    "clf_lgr.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U9')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lgr.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 0.8242424242424242\n",
      "TREE 0.7575757575757576\n",
      "NBG 0.8121212121212121\n",
      "LGR 0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM\", clf_svm.score(test_x_vectors, test_y))\n",
    "print(\"TREE\", clf_tree.score(test_x_vectors, test_y))\n",
    "print(\"NBG\", clf_nbg.score(test_x_vectors.toarray(), test_y))\n",
    "print(\"LGR\", clf_lgr.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_svm = clf_svm.predict(test_x_vectors)\n",
    "test_pred_tree = clf_tree.predict(test_x_vectors)\n",
    "test_pred_nbg = clf_nbg.predict(test_x_vectors.toarray())\n",
    "test_pred_lgr = clf_lgr.predict(test_x_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 SVM [0.91319444 0.21052632 0.22222222]\n",
      "F1 TREE [0.86725664 0.14705882 0.        ]\n",
      "F1 NBG [0.89678511 0.08510638 0.09090909]\n",
      "F1 LGR [0.91370558 0.12244898 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"F1 SVM\", f1_score(test_y, test_pred_svm, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(\"F1 TREE\", f1_score(test_y, test_pred_tree, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(\"F1 NBG\", f1_score(test_y, test_pred_nbg, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(\"F1 LGR\", f1_score(test_y, test_pred_lgr, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with a bigger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare new data (2)\n",
    "import json\n",
    "file_name2 = \"./data/Books_small_10000.json\"\n",
    "reviews2 = []\n",
    "with open(file_name2) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews2.append(Review(review['reviewText'], review['overall']))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "training2, test2 = train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "\n",
    "train2_x = [x.text for x in training2]\n",
    "train2_y = [x.sentiment for x in training2]\n",
    "\n",
    "test2_x = [x.text for x in test2]\n",
    "test2_y = [x.sentiment for x in test2]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectorizer.fit(train_x)\n",
    "train2_x_vectors = vectorizer.transform(train2_x)\n",
    "test2_x_vectors = vectorizer.transform(test2_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buildind models (2)\n",
    "from sklearn import svm\n",
    "clf2_svm = svm.SVC(kernel=\"linear\")\n",
    "clf2_svm.fit(train2_x_vectors, train2_y)\n",
    "\n",
    "from sklearn import tree\n",
    "clf2_tree = tree.DecisionTreeClassifier()\n",
    "clf2_tree.fit(train2_x_vectors, train2_y)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf2_nbg = GaussianNB()\n",
    "clf2_nbg.fit(train2_x_vectors.toarray(), train2_y)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf2_lgr = LogisticRegression()\n",
    "clf2_lgr.fit(train2_x_vectors, train2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM2 0.8242424242424242\n",
      "TREE2 0.7575757575757576\n",
      "NBG2 0.8121212121212121\n",
      "LGR2 0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "print(\"SVM2\", clf2_svm.score(test2_x_vectors, test2_y))\n",
    "print(\"TREE2\", clf2_tree.score(test2_x_vectors, test2_y))\n",
    "print(\"NBG2\", clf2_nbg.score(test2_x_vectors.toarray(), test2_y))\n",
    "print(\"LGR2\", clf2_lgr.score(test2_x_vectors, test2_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 SVM2 [0.91319444 0.21052632 0.22222222]\n",
      "F1 TREE2 [0.86772487 0.12903226 0.        ]\n",
      "F1 NBG2 [0.89678511 0.08510638 0.09090909]\n",
      "F1 LGR2 [0.91370558 0.12244898 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "test2_pred_svm = clf2_svm.predict(test2_x_vectors)\n",
    "test2_pred_tree = clf2_tree.predict(test2_x_vectors)\n",
    "test2_pred_nbg = clf2_nbg.predict(test2_x_vectors.toarray())\n",
    "test2_pred_lgr = clf2_lgr.predict(test2_x_vectors)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"F1 SVM2\", f1_score(test2_y, test2_pred_svm, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(\"F1 TREE2\", f1_score(test2_y, test2_pred_tree, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(\"F1 NBG2\", f1_score(test2_y, test2_pred_nbg, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(\"F1 LGR2\", f1_score(test2_y, test2_pred_lgr, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way to vectorize text\n",
    "This time taking into account word frecuency. The most a word appears in texts, the less important it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer3 = TfidfVectorizer()\n",
    "\n",
    "vectorizer3.fit(train_x)\n",
    "train3_x_vectors = vectorizer.transform(train2_x)\n",
    "test3_x_vectors = vectorizer.transform(test2_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<670x7372 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 41455 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3_x_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buildind models (3)\n",
    "from sklearn import svm\n",
    "clf3_svm = svm.SVC(kernel=\"linear\")\n",
    "clf3_svm.fit(train3_x_vectors, train2_y)\n",
    "\n",
    "from sklearn import tree\n",
    "clf3_tree = tree.DecisionTreeClassifier()\n",
    "clf3_tree.fit(train3_x_vectors, train2_y)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf3_nbg = GaussianNB()\n",
    "clf3_nbg.fit(train3_x_vectors.toarray(), train2_y)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf3_lgr = LogisticRegression()\n",
    "clf3_lgr.fit(train3_x_vectors, train2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM2 0.8242424242424242\n",
      "TREE2 0.7787878787878788\n",
      "NBG2 0.8121212121212121\n",
      "LGR2 0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "print(\"SVM2\", clf3_svm.score(test3_x_vectors, test2_y))\n",
    "print(\"TREE2\", clf3_tree.score(test3_x_vectors, test2_y))\n",
    "print(\"NBG2\", clf3_nbg.score(test3_x_vectors.toarray(), test2_y))\n",
    "print(\"LGR2\", clf3_lgr.score(test3_x_vectors, test2_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F3 SVM2 [0.91319444 0.21052632 0.22222222]\n",
      "F3 TREE2 [0.87609075 0.16666667 0.07407407]\n",
      "F3 NBG2 [0.89678511 0.08510638 0.09090909]\n",
      "F3 LGR2 [0.91370558 0.12244898 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "test3_pred_svm = clf3_svm.predict(test3_x_vectors)\n",
    "test3_pred_tree = clf3_tree.predict(test3_x_vectors)\n",
    "test3_pred_nbg = clf3_nbg.predict(test3_x_vectors.toarray())\n",
    "test3_pred_lgr = clf3_lgr.predict(test3_x_vectors)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"F3 SVM2\", f1_score(test2_y, test3_pred_svm, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(\"F3 TREE2\", f1_score(test2_y, test3_pred_tree, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(\"F3 NBG2\", f1_score(test2_y, test3_pred_nbg, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(\"F3 LGR2\", f1_score(test2_y, test3_pred_lgr, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the models (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [1, 4, 8, 16, 32], 'kernel': ['linear', 'rbf']})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = { \"kernel\": [\"linear\", \"rbf\"], \"C\": [1,4,8,16,32]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.1005383 , 0.15210547, 0.09614034, 0.15190659, 0.09634075,\n",
       "        0.18328671, 0.0989388 , 0.19427948, 0.09654088, 0.18728409]),\n",
       " 'std_fit_time': array([0.00679542, 0.00749027, 0.00386576, 0.01307642, 0.00279737,\n",
       "        0.02459818, 0.00428597, 0.00877153, 0.00454031, 0.00633983]),\n",
       " 'mean_score_time': array([0.01838851, 0.02658391, 0.01798887, 0.02638311, 0.01838846,\n",
       "        0.02678318, 0.01858792, 0.02698388, 0.01858768, 0.02558455]),\n",
       " 'std_score_time': array([0.00162379, 0.00080007, 0.00167266, 0.00048895, 0.0010191 ,\n",
       "        0.00097917, 0.00135556, 0.00063264, 0.00233082, 0.00048918]),\n",
       " 'param_C': masked_array(data=[1, 1, 4, 4, 8, 8, 16, 16, 32, 32],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 4, 'kernel': 'linear'},\n",
       "  {'C': 4, 'kernel': 'rbf'},\n",
       "  {'C': 8, 'kernel': 'linear'},\n",
       "  {'C': 8, 'kernel': 'rbf'},\n",
       "  {'C': 16, 'kernel': 'linear'},\n",
       "  {'C': 16, 'kernel': 'rbf'},\n",
       "  {'C': 32, 'kernel': 'linear'},\n",
       "  {'C': 32, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.76119403, 0.82835821, 0.74626866, 0.82835821, 0.74626866,\n",
       "        0.82089552, 0.74626866, 0.80597015, 0.74626866, 0.79104478]),\n",
       " 'split1_test_score': array([0.81343284, 0.82835821, 0.81343284, 0.82835821, 0.81343284,\n",
       "        0.8358209 , 0.81343284, 0.82835821, 0.81343284, 0.82089552]),\n",
       " 'split2_test_score': array([0.82089552, 0.82089552, 0.81343284, 0.82089552, 0.81343284,\n",
       "        0.82089552, 0.81343284, 0.81343284, 0.81343284, 0.82089552]),\n",
       " 'split3_test_score': array([0.82089552, 0.82089552, 0.79104478, 0.82089552, 0.79104478,\n",
       "        0.81343284, 0.79104478, 0.81343284, 0.79104478, 0.80597015]),\n",
       " 'split4_test_score': array([0.79104478, 0.82089552, 0.78358209, 0.82089552, 0.78358209,\n",
       "        0.80597015, 0.78358209, 0.79850746, 0.78358209, 0.80597015]),\n",
       " 'mean_test_score': array([0.80149254, 0.8238806 , 0.78955224, 0.8238806 , 0.78955224,\n",
       "        0.81940299, 0.78955224, 0.8119403 , 0.78955224, 0.80895522]),\n",
       " 'std_test_score': array([0.02292879, 0.00365595, 0.02470589, 0.00365595, 0.02470589,\n",
       "        0.00990037, 0.02470589, 0.00990037, 0.02470589, 0.01116913]),\n",
       " 'rank_test_score': array([6, 1, 7, 1, 7, 3, 7, 4, 7, 5])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 5,\n",
       " 'error_score': nan,\n",
       " 'estimator__C': 1.0,\n",
       " 'estimator__break_ties': False,\n",
       " 'estimator__cache_size': 200,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__coef0': 0.0,\n",
       " 'estimator__decision_function_shape': 'ovr',\n",
       " 'estimator__degree': 3,\n",
       " 'estimator__gamma': 'scale',\n",
       " 'estimator__kernel': 'rbf',\n",
       " 'estimator__max_iter': -1,\n",
       " 'estimator__probability': False,\n",
       " 'estimator__random_state': None,\n",
       " 'estimator__shrinking': True,\n",
       " 'estimator__tol': 0.001,\n",
       " 'estimator__verbose': False,\n",
       " 'estimator': SVC(),\n",
       " 'iid': 'deprecated',\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'kernel': ['linear', 'rbf'], 'C': [1, 4, 8, 16, 32]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM T 0.8242424242424242\n",
      "F1 SVM T [0.91319444 0.21052632 0.22222222]\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM T\", clf_svm.score(test_x_vectors, test_y))\n",
    "print(\"F1 SVM T\", f1_score(test_y, test_pred_svm, average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./models/sentiment_classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./my_notebooks1/models/sentiment_classifier.pkl\", \"rb\") as f:\n",
    "    loaded_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE',\n",
       "       'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_clf.predict(test_x_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
